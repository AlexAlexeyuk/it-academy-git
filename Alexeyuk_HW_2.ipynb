{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Untitled12.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QteP4TiCoNb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.notebook_repr_html', False)\n",
        "pd.set_option('display.max_columns', 8)\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.width', 80)\n",
        "\n",
        "\n",
        "with open('Dianetics.txt', 'r', encoding = 'utf-16') as dianetics:\n",
        "    dntx = dianetics.read()\n",
        "lenth_of_sent = []\n",
        "dianetics_pron = re.sub(r'[.!?]\\s',r'stop_scentence', dntx) #сделал замену \n",
        "#пунктуции на \"стоп_предложение\"\n",
        "sentences = len(dianetics_pron.split('stop_scentence')) # сделал список и \n",
        "#посчитал кол-во предложений\n",
        "full_text = dianetics_pron.split('stop_scentence')\n",
        "for sentence in full_text:\n",
        "    lenth_of_sent.append(len(sentence))\n",
        "print(\"Amoutn of sentences is: \" + str(sentences), \", quantity of words in \\\n",
        "      #every sentence: \" +  str(lenth_of_sent) )\n",
        "\n",
        "series_lenth_of_sentences = pd.Series(lenth_of_sent)\n",
        "df = pd.DataFrame(series_lenth_of_sentences, columns=[\"Lenth of sentences\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ1U0Oo7ouw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dntx = re.sub(r'[^\\w\\s]+|[\\d]+', r'', dianetics.read().strip()).lower() # уби- \n",
        "                                  #раем пунктуцию и делаем весь текст прописным\n",
        "dntx = re.sub(r'\\([^()]_*\\)', '', dntx).split() # убрали всё лишнее из нашего \n",
        "#текста\n",
        "d = {}\n",
        "for i in dntx:\n",
        "    d[i] = d.get(i, 0) + 1 # создали словарь\n",
        "list_d = list(d.items())\n",
        "list_d.sort(key=lambda i: i[1]) # посортируем значения по возрастанию\n",
        "rev_lst = list_d[::-1]\n",
        "top_100_words = rev_lst[:100] # будем отображать топ 100\n",
        "df = pd.DataFrame(top_100_words, columns=[\"words\", \"words frequency\"])\n",
        "grouped = df.groupby([\"words\"])\n",
        "\n",
        "df_with_index = df.set_index(['words']) # сделал слова индексами\n",
        "df_with_index.plot.barh() # построение гистограммы ( топ 100 слов в тексте)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}